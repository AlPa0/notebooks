{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "02_basics_PlutonAI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlelarge/dataflowr/blob/master/PlutonAI/02_basics_PlutonAI_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YmJE2a4N8We0"
      },
      "source": [
        "# Lesson 2: PyTorch tensors and automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOgNQwiv8We1",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "smvq6dbY8We4",
        "colab": {}
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vURcLof_8We8"
      },
      "source": [
        "Tensors are used to encode the signal to process, but also the internal states and parameters of models.\n",
        "\n",
        "**Manipulating data through this constrained structure allows to use CPUs and GPUs at peak performance.**\n",
        "\n",
        "Construct a 3x5 matrix, uninitialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c9tmMiNo8We-",
        "colab": {}
      },
      "source": [
        "x = torch.empty(3,5)\n",
        "print(x.dtype)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tlonXyHu8WfB"
      },
      "source": [
        "If you got an error this [stackoverflow link](https://stackoverflow.com/questions/50617917/overflow-when-unpacking-long-pytorch) might be useful..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlY-hwAY8WfB",
        "colab": {}
      },
      "source": [
        "x = torch.randn(3,5)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7g19ZvvL8WfD",
        "colab": {}
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZPjoP9Ec8WfG"
      },
      "source": [
        "torch.Size is in fact a [tuple](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences), so it supports the same operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rgVPlppm8WfG",
        "colab": {}
      },
      "source": [
        "x.size()[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CY87gW168WfI",
        "colab": {}
      },
      "source": [
        "x.size() == (3,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jeUshrFT8WfK"
      },
      "source": [
        "### Bridge to numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1cDkoT98WfM",
        "colab": {}
      },
      "source": [
        "y = x.numpy()\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2DdMiBVY8WfO",
        "colab": {}
      },
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a.dtype)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg-kloHeB_hR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = b.long()\n",
        "print(c.dtype, c)\n",
        "print(b.dtype, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZLbt9C38WfQ",
        "colab": {}
      },
      "source": [
        "xr = torch.randn(3, 5)\n",
        "print(xr.dtype, xr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T5nYMEcM8WfS",
        "colab": {}
      },
      "source": [
        "resb = xr + b\n",
        "resb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGTfk0M9B_hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resc = xr + c\n",
        "resc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuZ0-dswB_hf",
        "colab_type": "text"
      },
      "source": [
        "Be careful with types!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jdin_2zB_hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resb == resc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn7Xp9dpB_hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(precision=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipyVIQiKB_hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resb[0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEdzZjHhB_hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resc[0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkYkbUJNB_hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resc[0,1].dtype"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCBKNjLdB_hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xr[0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGdO-oaRB_hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(precision=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kt-CZCaZ8WgO"
      },
      "source": [
        "### [Broadcasting](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
        "\n",
        "Broadcasting automagically expands dimensions by replicating coefficients, when it is necessary to perform operations.\n",
        "\n",
        "1. If one of the tensors has fewer dimensions than the other, it is reshaped by adding as many dimensions of size 1 as necessary in the front; then\n",
        "2. for every mismatch, if one of the two tensor is of size one, it is expanded along this axis by replicating  coefficients.\n",
        "\n",
        "If there is a tensor size mismatch for one of the dimension and neither of them is one, the operation fails."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvB3V_ek8WgP",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
        "print(A.size())\n",
        "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
        "print(B.size())\n",
        "C = A + B"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aqqe1aTr8WgQ",
        "colab": {}
      },
      "source": [
        "C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvj9kBUCB_h3",
        "colab_type": "text"
      },
      "source": [
        "The original (column-)vector\n",
        "\\begin{eqnarray*}\n",
        "A = \\left( \\begin{array}{c}\n",
        "1\\\\\n",
        "2\\\\\n",
        "3\\\\\n",
        "4\\\\\n",
        "\\end{array}\\right)\n",
        "\\end{eqnarray*}\n",
        "is transformed into the matrix \n",
        "\\begin{eqnarray*}\n",
        "A = \\left( \\begin{array}{ccccc}\n",
        "1&1&1&1&1\\\\\n",
        "2&2&2&2&2\\\\\n",
        "3&3&3&3&3\\\\\n",
        "4&4&4&4&4\n",
        "\\end{array}\\right)\n",
        "\\end{eqnarray*}\n",
        "and the original (row-)vector\n",
        "\\begin{eqnarray*}\n",
        "C = (5,-5,5,-5,5)\n",
        "\\end{eqnarray*}\n",
        "is transformed into the matrix\n",
        "\\begin{eqnarray*}\n",
        "C = \\left( \\begin{array}{ccccc}\n",
        "5&-5&5&-5&5\\\\\n",
        "5&-5&5&-5&5\\\\\n",
        "5&-5&5&-5&5\\\\\n",
        "5&-5&5&-5&5\n",
        "\\end{array}\\right)\n",
        "\\end{eqnarray*}\n",
        "so that summing these matrices gives:\n",
        "\\begin{eqnarray*}\n",
        "A+C = \\left( \\begin{array}{ccccc}\n",
        "6&-4&6&-4&6\\\\\n",
        "7&-3&7&-3&7\\\\\n",
        "8&-2&8&-2&8\\\\\n",
        "9&-1&9&-1&9\n",
        "\\end{array}\\right)\n",
        "\\end{eqnarray*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq32MIeZB_h3",
        "colab_type": "text"
      },
      "source": [
        "### In-place modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V4Qvh2JB_h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VptqIf-0B_h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TlLf2SSZ8WfY",
        "colab": {}
      },
      "source": [
        "print(x+xr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jk8j_AhL8Wfa",
        "colab": {}
      },
      "source": [
        "x.add_(xr)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KmB6aFc08Wfc"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an ```_```\n",
        "\n",
        "For example: ```x.fill_(y)```, ```x.t_()```, will change ```x```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rzb4jk-d8Wfd",
        "colab": {}
      },
      "source": [
        "print(x.t())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNXvqa_38Wff",
        "colab": {}
      },
      "source": [
        "x.t_()\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zO4O1rJD8Wfi"
      },
      "source": [
        "### Shared memory\n",
        "\n",
        "Also be careful, changing the torch tensor modify the numpy array and vice-versa...\n",
        "\n",
        "This is explained in the PyTorch documentation [here](https://pytorch.org/docs/stable/torch.html#torch.from_numpy):\n",
        "The returned tensor by `torch.from_numpy` and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYOR2MzI8Wfj",
        "colab": {}
      },
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZP8DJXaC8Wfl",
        "colab": {}
      },
      "source": [
        "a[2] = 0\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ixqe4FEB_iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b[3] = 5\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahC2FkEGB_iN",
        "colab_type": "text"
      },
      "source": [
        "### Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Aq_IjCa8Wfo",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eZ9T7v3L8Wfq",
        "colab": {}
      },
      "source": [
        "#device = torch.device('cpu')\n",
        "device = torch.device('cuda') # Uncomment this to run on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BQv3WhHn8Wft",
        "colab": {}
      },
      "source": [
        "x.device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eKY8kHv_8Wfw",
        "colab": {}
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z,z.type())\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1A7Q5VYK8Wfx",
        "colab": {}
      },
      "source": [
        "x = torch.randn(1)\n",
        "x = x.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EnzdVsQW8HR3",
        "colab": {}
      },
      "source": [
        "x.device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6DzbPRKV8Wfz",
        "colab": {}
      },
      "source": [
        "# the following line is only useful if CUDA is available\n",
        "x = x.data\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QdtofUO78Wf1"
      },
      "source": [
        "# Simple interfaces to standard image data-bases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppop1eqWB_if",
        "colab_type": "text"
      },
      "source": [
        "An example, the [CIFAR10](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.CIFAR10) dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7O6lDC88Wf1",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "data_dir = 'content/data'\n",
        "\n",
        "cifar = torchvision.datasets.CIFAR10(data_dir, train = True, download = True)\n",
        "cifar.data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfIsAgwGB_ih",
        "colab_type": "text"
      },
      "source": [
        "Documentation about the [`permute`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute) operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "37KuS3m-B_ii",
        "colab": {}
      },
      "source": [
        "x = torch.from_numpy(cifar.data).permute(0,3,1,2).float()\n",
        "x = x / 255\n",
        "print(x.type(), x.size(), x.min().item(), x.max().item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfrAC1GaB_ik",
        "colab_type": "text"
      },
      "source": [
        "Documentation about the [`narrow(input, dim, start, length)`](https://pytorch.org/docs/stable/torch.html#torch.narrow) operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZUzzXJD8Wf3",
        "colab": {}
      },
      "source": [
        "# Narrows to the first images, converts to float\n",
        "x = torch.narrow(x, 0, 0, 48)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5J3ohUMB_im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eVT7H5jS8Wf8",
        "colab": {}
      },
      "source": [
        "# Showing images\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "    \n",
        "show(torchvision.utils.make_grid(x, nrow = 12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9WuxYev_8Wf_",
        "colab": {}
      },
      "source": [
        "# Kills the green and blue channels\n",
        "x.narrow(1, 1, 2).fill_(0)\n",
        "show(torchvision.utils.make_grid(x, nrow = 12))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QWopk2GX8WgB"
      },
      "source": [
        "# Autograd: automatic differentiation\n",
        "\n",
        "When executing tensor operations, PyTorch can automatically construct on-the-fly the graph of operations to compute the gradient of any quantity with respect to any tensor involved.\n",
        "\n",
        "To be more concrete, we introduce the following example: we consider parameters $w\\in \\mathbb{R}$ and $b\\in \\mathbb{R}$ with the corresponding function:\n",
        "\\begin{eqnarray*}\n",
        "\\ell = \\left(\\exp(wx+b) - y^* \\right)^2\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Our goal here, will be to compute the following partial derivatives:\n",
        "\\begin{eqnarray*}\n",
        "\\frac{\\partial \\ell}{\\partial w}\\mbox{ and, }\\frac{\\partial \\ell}{\\partial b}.\n",
        "\\end{eqnarray*}\n",
        "\n",
        "The reason for doing this will be clear when you will solve the practicals for this lesson!\n",
        "\n",
        "You can decompose this function as a composition of basic operations. This is call the forward pass on the graph of operations.\n",
        "![backprop1](https://mlelarge.github.io/dataflowr/PlutonAI/backprop1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78AWWCb9B_iu",
        "colab_type": "text"
      },
      "source": [
        "Let say we start with our model in `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TEixrqxB_iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = np.array([0.5])\n",
        "b = np.array([2])\n",
        "xx = np.array([0.5])#np.arange(0,1.5,.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ8DlM8lB_iw",
        "colab_type": "text"
      },
      "source": [
        "transform these into `tensor`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKl5570iB_ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx_t = torch.from_numpy(xx)\n",
        "w_t = torch.from_numpy(w)\n",
        "b_t = torch.from_numpy(b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9PwWnxYB_iz",
        "colab_type": "text"
      },
      "source": [
        "A `tensor` has a Boolean field `requires_grad`, set to `False` by default, which states if PyTorch should build the graph of operations so that gradients with respect to it can be computed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbWfbvtdB_iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_t.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rD3GLyB_i2",
        "colab_type": "text"
      },
      "source": [
        "We want to take derivative with respect to $w$ so we change this value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqS0CC8NB_i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_t.requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysa_qEvFB_i5",
        "colab_type": "text"
      },
      "source": [
        "We want to do the same thing for $b$ but the following line will produce an error!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pSa2V4yB_i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_t.requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL0X9fIsB_i8",
        "colab_type": "text"
      },
      "source": [
        "Reading the error message should allow you to correct the mistake!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imH8JSXxB_i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.float64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLSSIn5jB_jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_t = b_t.type(dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mpavg-B_jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_t.requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Melb8jo8B_jE",
        "colab_type": "text"
      },
      "source": [
        "We now compute the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elI91IulB_jF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fun(x,ystar):\n",
        "    y = torch.exp(w_t*x+b_t)\n",
        "    print(y)\n",
        "    return torch.sum((y-ystar)**2)\n",
        "\n",
        "ystar_t = torch.randn_like(xx_t)\n",
        "l_t = fun(xx_t,ystar_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5qpcse1B_jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WXzmCSdB_jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_t.requires_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJEjjKBFB_jK",
        "colab_type": "text"
      },
      "source": [
        "After the computation is finished, i.e. *forward pass*, you can call ```.backward()``` and have all the gradients computed automatically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1m1CowRB_jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(w_t.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTw9bl4DB_jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_t.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4_zWnJkB_jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(w_t.grad)\n",
        "print(b_t.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8fwcPgHB_jP",
        "colab_type": "text"
      },
      "source": [
        "Let's try to understand these numbers...\n",
        "\n",
        "![backprop2](https://mlelarge.github.io/dataflowr/PlutonAI/backprop2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDV9lByQB_jP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yy_t = torch.exp(w_t*xx_t+b_t)\n",
        "print(torch.sum(2*(yy_t-ystar_t)*yy_t*xx_t))\n",
        "print(torch.sum(2*(yy_t-ystar_t)*yy_t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMguUH4y8WgW"
      },
      "source": [
        "`tensor.backward()` accumulates the gradients in  the `grad` fields  of tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70jDhm91B_jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_t = fun(xx_t,ystar_t)\n",
        "l_t.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L5H8BQOs8WgW",
        "colab": {}
      },
      "source": [
        "print(w_t.grad)\n",
        "print(b_t.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H2ZnVM5B_jU",
        "colab_type": "text"
      },
      "source": [
        "By default, `backward` deletes the computational graph when it is used so that you will get an error below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06_uW2EwB_jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l_t.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHxmIJj2B_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Manually zero the gradients\n",
        "w_t.grad.data.zero_()\n",
        "b_t.grad.data.zero_()\n",
        "l_t = fun(xx_t,ystar_t)\n",
        "l_t.backward(retain_graph=True)\n",
        "l_t.backward()\n",
        "print(w_t.grad)\n",
        "print(b_t.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v40jAQEE8Wgu"
      },
      "source": [
        "The gradients must be set to zero manually. Otherwise they will cumulate across several _.backward()_ calls. \n",
        "This accumulating behavior is desirable in particular to compute the gradient of a loss summed over several “mini-batches,” or the gradient of a sum of losses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZkT-mC9R8Wgy"
      },
      "source": [
        "# Playing with pytorch: linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XsESRui28Wgy"
      },
      "source": [
        "## Warm-up: Linear regression with numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FvAi4z478Wg0"
      },
      "source": [
        "Our model is:\n",
        "$$\n",
        "y_t = 2x^1_t-3x^2_t+1, \\quad t\\in\\{1,\\dots,30\\}\n",
        "$$\n",
        "\n",
        "Our task is given the 'observations' $(x_t,y_t)_{t\\in\\{1,\\dots,30\\}}$ to recover the weights $w^1=2, w^2=-3$ and the bias $b = 1$.\n",
        "\n",
        "In order to do so, we will solve the following optimization problem:\n",
        "$$\n",
        "\\underset{w^1,w^2,b}{\\operatorname{argmin}} \\sum_{t=1}^{30} \\left(w^1x^1_t+w^2x^2_t+b-y_t\\right)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_hSr09Qa8Wg1",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import random\n",
        "# generate random input data\n",
        "x = random((30,2))\n",
        "\n",
        "# generate labels corresponding to input data x\n",
        "y = np.dot(x, [2., -3.]) + 1.\n",
        "w_source = np.array([2., -3.])\n",
        "b_source  = np.array([1.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vclk_vje8Wg2",
        "colab": {}
      },
      "source": [
        "x[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S5F3fcVN8Wg6",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "def plot_figs(fig_num, elev, azim, x, y, weights, bias):\n",
        "    fig = plt.figure(fig_num, figsize=(4, 3))\n",
        "    plt.clf()\n",
        "    ax = Axes3D(fig, elev=elev, azim=azim)\n",
        "    ax.scatter(x[:, 0], x[:, 1], y)\n",
        "    ax.plot_surface(np.array([[0, 0], [1, 1]]),\n",
        "                    np.array([[0, 1], [0, 1]]),\n",
        "                    (np.dot(np.array([[0, 0, 1, 1],\n",
        "                                          [0, 1, 0, 1]]).T, weights) + bias).reshape((2, 2)),\n",
        "                    alpha=.5)\n",
        "    ax.set_xlabel('x_1')\n",
        "    ax.set_ylabel('x_2')\n",
        "    ax.set_zlabel('y')\n",
        "    \n",
        "def plot_views(x, y, w, b):\n",
        "    #Generate the different figures from different views\n",
        "    elev = 43.5\n",
        "    azim = -110\n",
        "    plot_figs(1, elev, azim, x, y, w, b[0])\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8l7XSyJM8Wg8",
        "colab": {}
      },
      "source": [
        "plot_views(x, y, w_source, b_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FCZAMgQn8Wg9"
      },
      "source": [
        "In vector form, we define:\n",
        "$$\n",
        "\\hat{y}_t = {\\bf w}^T{\\bf x}_t+b\n",
        "$$\n",
        "and we want to minimize the loss given by:\n",
        "$$\n",
        "loss = \\sum_t\\underbrace{\\left(\\hat{y}_t-y_t \\right)^2}_{loss_t}.\n",
        "$$\n",
        "\n",
        "To minimize the loss we first compute the gradient of each $loss_t$:\n",
        "\\begin{eqnarray*}\n",
        "\\frac{\\partial{loss_t}}{\\partial w^1} &=& 2x^1_t\\left({\\bf w}^T{\\bf x}_t+b-y_t \\right)\\\\\n",
        "\\frac{\\partial{loss_t}}{\\partial w^2} &=& 2x^2_t\\left({\\bf w}^T{\\bf x}_t+b-y_t \\right)\\\\\n",
        "\\frac{\\partial{loss_t}}{\\partial b} &=& 2\\left({\\bf w}^T{\\bf x}_t+b-y_t \\right)\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Note that the actual gradient of the loss is given by:\n",
        "$$\n",
        "\\frac{\\partial{loss}}{\\partial w^1} =\\sum_t \\frac{\\partial{loss_t}}{\\partial w^1},\\quad\n",
        "\\frac{\\partial{loss}}{\\partial w^2} =\\sum_t \\frac{\\partial{loss_t}}{\\partial w^2},\\quad\n",
        "\\frac{\\partial{loss}}{\\partial b} =\\sum_t \\frac{\\partial{loss_t}}{\\partial b}\n",
        "$$\n",
        "\n",
        "For one epoch, **(Batch) Gradient Descent** updates the weights and bias as follows:\n",
        "\\begin{eqnarray*}\n",
        "w^1_{new}&=&w^1_{old}-\\alpha\\frac{\\partial{loss}}{\\partial w^1} \\\\\n",
        "w^2_{new}&=&w^2_{old}-\\alpha\\frac{\\partial{loss}}{\\partial w^2} \\\\\n",
        "b_{new}&=&b_{old}-\\alpha\\frac{\\partial{loss}}{\\partial b},\n",
        "\\end{eqnarray*}\n",
        "\n",
        "and then we run several epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q2eUfQws8WhA",
        "colab": {}
      },
      "source": [
        "# randomly initialize learnable weights and bias\n",
        "w_init = random(2)\n",
        "b_init = random(1)\n",
        "\n",
        "w = w_init\n",
        "b = b_init\n",
        "print(\"initial values of the parameters:\", w, b )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "scrolled": true,
        "id": "z1kUBCujB_jk",
        "colab": {}
      },
      "source": [
        "# our model forward pass\n",
        "def forward(x):\n",
        "    return x.dot(w)+b\n",
        "\n",
        "# Loss function\n",
        "def loss(x, y):\n",
        "    y_pred = forward(x)\n",
        "    return (y_pred - y)**2 \n",
        "\n",
        "print(\"initial loss:\", np.sum([loss(x_val,y_val) for x_val, y_val in zip(x, y)]) )\n",
        "\n",
        "# compute gradient\n",
        "def gradient(x, y):  # d_loss/d_w, d_loss/d_c\n",
        "    return 2*(x.dot(w)+b - y)*x, 2 * (x.dot(w)+b - y)\n",
        " \n",
        "learning_rate = 1e-2\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    grad_w = np.array([0,0])\n",
        "    grad_b = np.array(0)\n",
        "    l = 0\n",
        "    for x_val, y_val in zip(x, y):\n",
        "        grad_w = np.add(grad_w,gradient(x_val, y_val)[0])\n",
        "        grad_b = np.add(grad_b,gradient(x_val, y_val)[1])\n",
        "        l += loss(x_val, y_val)\n",
        "    w = w - learning_rate * grad_w\n",
        "    b = b - learning_rate * grad_b\n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",l[0])\n",
        "\n",
        "# After training\n",
        "print(\"estimation of the parameters:\", w, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BO_DKaes8WhB",
        "colab": {}
      },
      "source": [
        "plot_views(x, y, w, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQz2GoXh8WhC"
      },
      "source": [
        "## Linear regression with tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9KKfUKVn8WhD",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aLQeUOFi8WhF",
        "colab": {}
      },
      "source": [
        "x_t = torch.from_numpy(x).type(dtype)\n",
        "y_t = torch.from_numpy(y).type(dtype).unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1MExDafv8WhG"
      },
      "source": [
        "This is an implementation of **(Batch) Gradient Descent** with tensors.\n",
        "\n",
        "Note that in the main loop, the functions loss_t and gradient_t are always called with the same inputs: they can easily be incorporated into the loop (we'll do that below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5tWn-6PC8WhH",
        "colab": {}
      },
      "source": [
        "w_init_t = torch.from_numpy(w_init).type(dtype)\n",
        "b_init_t = torch.from_numpy(b_init).type(dtype)\n",
        "\n",
        "w_t = w_init_t.clone()\n",
        "w_t.unsqueeze_(1)\n",
        "b_t = b_init_t.clone()\n",
        "b_t.unsqueeze_(1)\n",
        "print(\"initial values of the parameters:\", w_t, b_t )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ovfMuTVB_jr",
        "colab": {}
      },
      "source": [
        "# our model forward pass\n",
        "def forward_t(x):\n",
        "    return x.mm(w_t)+b_t\n",
        "\n",
        "# Loss function\n",
        "def loss_t(x, y):\n",
        "    y_pred = forward_t(x)\n",
        "    return (y_pred - y).pow(2).sum()\n",
        "\n",
        "# compute gradient\n",
        "def gradient_t(x, y):  # d_loss/d_w, d_loss/d_c\n",
        "    return 2*torch.mm(torch.t(x),x.mm(w_t)+b_t - y), 2 * (x.mm(w_t)+b_t - y).sum()\n",
        "\n",
        "learning_rate = 1e-2\n",
        "for epoch in range(10):\n",
        "    l_t = loss_t(x_t,y_t)\n",
        "    grad_w, grad_b = gradient_t(x_t,y_t)\n",
        "    w_t = w_t-learning_rate*grad_w\n",
        "    b_t = b_t-learning_rate*grad_b\n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",l_t)\n",
        "\n",
        "# After training\n",
        "print(\"estimation of the parameters:\", w_t, b_t )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bTrqi-ux8WhJ"
      },
      "source": [
        "## Linear regression with Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LTH6VOMz8WhJ",
        "colab": {}
      },
      "source": [
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "w_v = w_init_t.clone().unsqueeze(1)\n",
        "w_v.requires_grad_(True)\n",
        "b_v = b_init_t.clone().unsqueeze(1)\n",
        "b_v.requires_grad_(True)\n",
        "print(\"initial values of the parameters:\", w_v.data, b_v.data )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oHgm3N8Y8WhK"
      },
      "source": [
        "An implementation of **(Batch) Gradient Descent** without computing explicitly the gradient and using autograd instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4sdOF0e8WhL",
        "colab": {}
      },
      "source": [
        "for epoch in range(10):\n",
        "    y_pred = x_t.mm(w_v)+b_v\n",
        "    loss = (y_pred - y_t).pow(2).sum()\n",
        "    \n",
        "    # Use autograd to compute the backward pass. This call will compute the\n",
        "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
        "    # After this call w.grad and b.grad will be tensors holding the gradient\n",
        "    # of the loss with respect to w and b respectively.\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update weights using gradient descent. For this step we just want to mutate\n",
        "    # the values of w_v and b_v in-place; we don't want to build up a computational\n",
        "    # graph for the update steps, so we use the torch.no_grad() context manager\n",
        "    # to prevent PyTorch from building a computational graph for the updates\n",
        "    with torch.no_grad():\n",
        "        w_v -= learning_rate * w_v.grad\n",
        "        b_v -= learning_rate * b_v.grad\n",
        "    \n",
        "    # Manually zero the gradients after updating weights\n",
        "    # otherwise gradients will be acumulated after each .backward()\n",
        "    w_v.grad.zero_()\n",
        "    b_v.grad.zero_()\n",
        "    \n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",loss.data.item())\n",
        "\n",
        "# After training\n",
        "print(\"estimation of the parameters:\", w_v.data, b_v.data.t() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W720TY4R8WhN"
      },
      "source": [
        "## Linear regression with neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6VgMVkn48WhN"
      },
      "source": [
        "An implementation of **(Batch) Gradient Descent** using the nn package. Here we have a super simple model with only one layer and no activation function!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plEHj42d8WhO",
        "colab": {}
      },
      "source": [
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Variables for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2, 1),\n",
        ")\n",
        "\n",
        "for m in model.children():\n",
        "    m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "    m.bias.data = b_init_t.clone()\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "# switch to train mode\n",
        "model.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Variable of input data to the Module and it produces\n",
        "    # a Variable of output data.\n",
        "    y_pred = model(x_t)\n",
        "  \n",
        "    # Note this operation is equivalent to: pred = model.forward(x_v)\n",
        "\n",
        "    # Compute and print loss. We pass Variables containing the predicted and true\n",
        "    # values of y, and the loss function returns a Variable containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y_t)\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Variables with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its data and gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param.data -= learning_rate * param.grad\n",
        "        \n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",loss.data.item())\n",
        "\n",
        "# After training\n",
        "print(\"estimation of the parameters:\")\n",
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gus-YF9p8WhP"
      },
      "source": [
        "Last step, we use directly the optim package to update the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VbF5gYV8WhP",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2, 1),\n",
        ")\n",
        "\n",
        "for m in model.children():\n",
        "    m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "    m.bias.data = b_init_t.clone()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    y_pred = model(x_t)\n",
        "    loss = loss_fn(y_pred, y_t)\n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",loss.item())\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "# After training\n",
        "print(\"estimation of the parameters:\")\n",
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFxayCILB_j2",
        "colab_type": "text"
      },
      "source": [
        "## Remark\n",
        "\n",
        "This problem can be solved in 3 lines of code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q9sz3M8B_j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb_t = torch.cat((x_t,torch.ones(30).unsqueeze(1)),1)\n",
        "sol, _ =torch.lstsq(y_t,xb_t)\n",
        "sol[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IY_I9v3o8WhQ"
      },
      "source": [
        "## Exercise: Play with the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "It_tRuXs8WhQ"
      },
      "source": [
        "Change the number of samples from 30 to 300. What happens? How to correct it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRk1zgSv8WhR",
        "colab": {}
      },
      "source": [
        "x = random((300,2))\n",
        "y = np.dot(x, [2., -3.]) + 1.\n",
        "x_t = torch.from_numpy(x).type(dtype)\n",
        "y_t = torch.from_numpy(y).type(dtype).unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-xOCI6z8WhS",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2, 1),\n",
        ")\n",
        "\n",
        "for m in model.children():\n",
        "    m.weight.data = w_init_t.clone().unsqueeze(0)\n",
        "    m.bias.data = b_init_t.clone()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction = 'sum')\n",
        "\n",
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    y_pred = model(x_t)\n",
        "    loss = loss_fn(y_pred, y_t)\n",
        "    print(\"progress:\", \"epoch:\", epoch, \"loss\",loss.item())\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "# After training\n",
        "print(\"estimation of the parameters:\")\n",
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAiS-TfqDOMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}